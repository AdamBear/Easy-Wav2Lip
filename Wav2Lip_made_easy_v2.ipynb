{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anothermartz/Easy-Wav2Lip/blob/main/Wav2Lip_made_easy_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkoF-mm8CGfB"
      },
      "source": [
        "Make sure to click ðŸ‘† that button to copy it your own Google Drive first!\n",
        "\n",
        "# Wav2Lip-HQ made easy!\n",
        "\n",
        "GitHub: https://github.com/anothermartz/Easy-Wav2Lip\n",
        "\n",
        "* Code adapted to google colab from [wav2lip-hq-updated-ESRGAN](https://github.com/GucciFlipFlops1917/wav2lip-hq-updated-ESRGAN) by [GucciFlipFlops1917](https://github.com/GucciFlipFlops1917)\n",
        "\n",
        "* Which fixes and improves the depreciated [Wav2LipHQ](https://github.com/Markfryazino/wav2lip-hq)\n",
        "\n",
        "* Which is based on the original [Wav2Lip](https://github.com/Rudrabha/Wav2Lip)\n",
        "\n",
        "Not only was this built on the shoulders of giants, I'm not even very good at coding and I practically used Bing AI chat to do it all for me.\n",
        "\n",
        "However I may offer some support in this discord:<br>\n",
        "Invite link: https://discord.gg/FNZR9ETwKY<br>\n",
        "Wav2Lip channel: https://discord.com/channels/667279414681272320/1076077584330280991"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFOs0q_SKzqG"
      },
      "source": [
        "# How to format your files for this colab:\n",
        "Video files:\n",
        "* Must be .mp4 (for now)\n",
        "* Must have a face in all frames\n",
        "* Small file in every way (try <720p, <60 seconds, <10mbps <b></b> bitrate etc. - Bigger files may work but are usually the reason it fails)\n",
        "\n",
        "Audio files:\n",
        "* Ideally just encode it into your .mp4 files\n",
        "* <b>OR</b>\n",
        "* Must be .wav\n",
        "* Same folder and filename as video files eg: File1.wav, File2.wav, File 3.wav\n",
        "\n",
        "Technically more formats are supported with Wav2Lip, but I've only coded it to support .mp4 and .wav for now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "lvmg_zr-9yaZ",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#@title <h1>Step 1: Setup \"Easy-Wav2Lip\"</h1> With one button: it's really that easy!\n",
        "#@markdown 1. ðŸ‘ˆ Click that little circle play button.\n",
        "#@markdown 2. If your files are on Google Drive (recommended), connect your Google Drive when prompted\n",
        "#@markdown <br><br> Alternatively, say \"no thanks\" and click the folder icon to the far left, right click and upload your files there.<br>If not using Google Drive, you may lose all processed files if not manually downloaded.\n",
        "\n",
        "#mount Google Drive\n",
        "print(\"Mounting Google Drive...\")\n",
        "GDrive = True\n",
        "from google.colab import drive\n",
        "try:\n",
        "  drive.mount('/content/drive')\n",
        "except:\n",
        "  from IPython.core.display import clear_output\n",
        "  clear_output()\n",
        "  print(\"...Not mounting Google Drive\")\n",
        "  GDrive = False\n",
        "\n",
        "print()\n",
        "print('Downloading and installing requirements - this usually takes 2-3 minutes, scroll down and start setting up Step 2!')\n",
        "print()\n",
        "\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "import warnings\n",
        "\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import sys\n",
        "#check GPU\n",
        "print(\"Checking GPU is enabled:\")\n",
        "if not tf.test.gpu_device_name():\n",
        "    sys.exit('No GPU in runtime. Please go to the \"Runtime\" menu, \"Change runtime type\" and select \"GPU\".')\n",
        "else:\n",
        "  gpu_name = torch.cuda.get_device_name(0)\n",
        "  gpu_name = gpu_name.replace(' ', '_')\n",
        "  print(f'GPU is {gpu_name}')\n",
        "\n",
        "#imports and stuff\n",
        "import csv\n",
        "import gdown\n",
        "import io\n",
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import shutil\n",
        "import subprocess\n",
        "\n",
        "from base64 import b64encode\n",
        "from numpy.lib import stride_tricks\n",
        "from IPython.display import HTML, Audio, clear_output\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.exceptions import DataConversionWarning\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "os.system('git clone https://github.com/anothermartz/Easy-Wav2Lip.git')\n",
        "os.chdir('Easy-Wav2Lip')\n",
        "os.system('pip3 install -r requirements.txt') \n",
        "from wav2lip_models import Wav2Lip\n",
        "from basicsr.utils.download_util import load_file_from_url\n",
        "from face_parsing import init_parser\n",
        "def load_model(path):\n",
        "\tmodel = Wav2Lip()\n",
        "\tprint(\"Load checkpoint from: {}\".format(path))\n",
        "\tcheckpoint = torch.load(path)\n",
        "\ts = checkpoint[\"state_dict\"]\n",
        "\tnew_s = {}\n",
        "\tfor k, v in s.items():\n",
        "\t\tnew_s[k.replace('module.', '')] = v\n",
        "\tmodel.load_state_dict(new_s)\n",
        "\tmodel = model.to(\"cuda\")\n",
        "\treturn model.eval()\n",
        "!pip install boto3 --quiet\n",
        "!pip install realesrgan --quiet\n",
        "#clear_output()\n",
        "import boto3\n",
        "from botocore.exceptions import NoCredentialsError\n",
        "#pre-download all models so that Step 2 is faster - I don't know how else to download gfpgan and codeformer files than to run them so I include a tiny video to process quickly.\n",
        "!wget \"https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth\" -O \"/content/Easy-Wav2Lip/weights/RealESRGAN_x4plus.pth\"\n",
        "!python inference.py --face \"/content/Easy-Wav2Lip/temp/initialize.mp4\" --audio \"/content/Easy-Wav2Lip/temp/initialize.mp4\" --outfile \"/content/Easy-Wav2Lip/temp/initialized_gfpgan.mp4\" --resize_factor 8 --enhance_face 'gfpgan'\n",
        "!python inference.py --face \"/content/Easy-Wav2Lip/temp/initialize.mp4\" --audio \"/content/Easy-Wav2Lip/temp/initialize.mp4\" --outfile \"/content/Easy-Wav2Lip/temp/initialized_codeformer.mp4\" --resize_factor 8 --enhance_face 'codeformer'\n",
        "#!wget \"https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\" -O \"face_detection/detection/sfd/s3fd.pth\"\n",
        "#clear_output()\n",
        "print('Downloading and installing requirements - this usually takes about 3 minutes, scroll down and start setting up Step 2!')\n",
        "print()\n",
        "s3_folder = 's3://anothermartz/wav2lip/'\n",
        "s3_access_key = 'AKIAZ7DRI6ZBVYXRXDOK'\n",
        "s3_secret_key = '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'\n",
        "s3 = boto3.client('s3', aws_access_key_id=s3_access_key, aws_secret_access_key=s3_secret_key)\n",
        "bucket_name = 'anothermartz'\n",
        "\n",
        "#---------------------------------functions!------------------------------------\n",
        "\n",
        "def showVideo(file_path):\n",
        "  \"\"\"Function to display video in Colab\"\"\"\n",
        "  mp4 = open(file_path,'rb').read()\n",
        "  data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "  display(HTML(\"\"\"\n",
        "  <video controls width=600>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "  </video>\n",
        "  \"\"\" % data_url))\n",
        "\n",
        "def get_video_details(filename):\n",
        "    cmd = ['ffprobe', '-v', 'error', '-show_format', '-show_streams', '-of', 'json', filename]\n",
        "    result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
        "    info = json.loads(result.stdout)\n",
        "\n",
        "    # Get video stream\n",
        "    video_stream = next(stream for stream in info['streams'] if stream['codec_type'] == 'video')\n",
        "\n",
        "    # Get resolution\n",
        "    width = int(video_stream['width'])\n",
        "    height = int(video_stream['height'])\n",
        "    resolution = width*height\n",
        "\n",
        "    # Get bitrate\n",
        "    bitrate = int(info['format']['bit_rate']) / 1_000_000\n",
        "\n",
        "    # Get length\n",
        "    length = float(info['format']['duration'])\n",
        "\n",
        "    return {'resolution': resolution, 'bitrate': bitrate, 'length': length}\n",
        "\n",
        "def predict_processing_time(input_resolution, input_bitrate, input_length, resolution_scale, upscaler):\n",
        "    filename = f'{upscaler}_with_{gpu_name}_stats.csv'\n",
        "    try:\n",
        "        # Load the data from the CSV file\n",
        "        data = pd.read_csv(filename, header=None)\n",
        "    except FileNotFoundError:\n",
        "        return None\n",
        "\n",
        "    # Split the data into input features and target variable\n",
        "    X = data.iloc[:, :-1]\n",
        "    y = data.iloc[:, -1]\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "    # Train a random forest regressor on the training data\n",
        "    regressor = RandomForestRegressor()\n",
        "    regressor.fit(X_train, y_train)\n",
        "\n",
        "    # Calculate the R-squared value on the test set\n",
        "    r_squared = regressor.score(X_test, y_test)\n",
        "\n",
        "    # Create a new row of data for the new video\n",
        "    new_video = [input_resolution, input_bitrate, input_length, resolution_scale]\n",
        "\n",
        "    # Predict the processing time of the new video\n",
        "    predicted_time = regressor.predict([new_video])\n",
        "    \n",
        "    return predicted_time, r_squared\n",
        "\n",
        "def format_time(seconds):\n",
        "    hours = int(seconds // 3600)\n",
        "    minutes = int((seconds % 3600) // 60)\n",
        "    seconds = int(seconds % 60)\n",
        "    \n",
        "    if hours > 0:\n",
        "        return f'{hours}h {minutes}m {seconds}s'\n",
        "    elif minutes > 0:\n",
        "        return f'{minutes}m {seconds}s'\n",
        "    else:\n",
        "        return f'{seconds}s'\n",
        "\n",
        "def store_processing_stats(input_resolution, input_bitrate, input_length, resolution_scale, upscaler, process_time):\n",
        "    filename = f'{upscaler}_with_{gpu_name}_stats.csv'\n",
        "    with open(filename, mode='a', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([input_resolution, input_bitrate, input_length, resolution_scale, process_time])\n",
        "\n",
        "\n",
        "def count_lines(stats_file):\n",
        "    with open(stats_file, 'r') as f:\n",
        "        return sum(1 for line in f)\n",
        "\n",
        "def remove_duplicates(stats_file):\n",
        "    df = pd.read_csv(stats_file)\n",
        "    df = df.drop_duplicates()\n",
        "    df.to_csv(stats_file, index=False)\n",
        "\n",
        "#------------------------------------------------------------------------------!\n",
        "\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "formatted_setup_time = format_time(elapsed_time)\n",
        "\n",
        "#clear_output()\n",
        "print()\n",
        "print(\"Installation complete, move to Step 2!\")\n",
        "print(f\"Execution time: {formatted_setup_time}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49bpPc22f-wR",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#------------------------------user inputs--------------------------------------\n",
        "#@markdown <h1>Step 2: Select video:</h1>\n",
        "input_path = \"\" #@param {type:\"string\"}\n",
        "#@markdown >ðŸ‘ˆ Look for the folder icon at the left edge of colab and find your video, right click it, copy path & paste it above\n",
        "#Batch_Process= True #@param {type:\"boolean\"}\n",
        "##@markdown >Disable if you just want to process one video (good for testing or fixing padding).\n",
        "output_suffix = \"_Wav2LipHQ\" #@param {type:\"string\"}\n",
        "#@markdown >This adds a suffix to your output files so that they don't overwite your originals\n",
        "preview_input = True #@param {type:\"boolean\"}\n",
        "#@markdown >Displays the video/audio while Wav2Lip does its thing, disabling saves some seconds.\n",
        "#@markdown <h1><br>Step 3: Tweak padding:</h1> (Up, Down, Left, Right) <br>\n",
        "#@markdown <b><br>Lower values typically look better on the mouth but can cause hard lines at the edges of the face (typically on the chin)</b>\n",
        "U = 0 #@param {type:\"slider\", min:0, max:100, step:1}\n",
        "D =  20 #@param {type:\"slider\", min:0, max:100, step:1}\n",
        "L =  0 #@param {type:\"slider\", min:0, max:100, step:1}\n",
        "R =  0 #@param {type:\"slider\", min:0, max:100, step:1}\n",
        "#@markdown Lower the output resolution for quicker rendering and better hiding of artifacts, at the cost of worse overall image quality:\n",
        "resolution_scale =  1 #@param {type:\"slider\", min:0.25, max:1, step:0.25}\n",
        "#@markdown Disable face detection smoothing which may fix artifacts, I'm not aware of any downsides to this:\n",
        "nosmooth = True #@param {type:\"boolean\"}\n",
        "#@markdown <h1><br>Step 4: Choose Upscaler Method:</h1> I suggest gfpgan but you can experiment with the others <br>\n",
        "upscaler = \"gfpgan\" #@param [\"gfpgan\", \"codeformer\", \"ESRGAN\"]\n",
        "#@markdown for use with codeformer only:\n",
        "fidelity = 0.75 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "#@markdown <h1></h1> I recommend 0.75 but have a play around to see what you like\n",
        "#@markdown <h1><br>Step 5: Click the little play button for this cell and wait for it to process.</h1>( or press ctrl + F10 )\n",
        "\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "#--------------------------variables generation---------------------------------\n",
        "# Check if path ends with .mp4 (will support more filetypes in the next version)\n",
        "file_type = os.path.splitext(input_path)[1]\n",
        "if not file_type ==\".mp4\":\n",
        "    sys.exit('File is not .mp4')\n",
        "else:\n",
        "  # Check if input file exists\n",
        "  if not os.path.exists(input_path):\n",
        "      sys.exit(f'Could not find file: {input_path}')\n",
        "  else:\n",
        "      # Extract filename\n",
        "      filename_pattern = r\"[^\\/]+(?=\\.\\w+$)\"\n",
        "      filename = re.search(filename_pattern, input_path).group()\n",
        "      # Extract folder path\n",
        "      folder_pattern = r\"^(.*\\/)[^\\/]+$\"\n",
        "      folder = re.search(folder_pattern, input_path).group(1)\n",
        "      # Extract filenumber for batch processing (coming in the future)\n",
        "      filenumber_pattern = r\"\\d+$\"\n",
        "      filenumber_match = re.search(filenumber_pattern, filename)\n",
        "      if filenumber_match:\n",
        "          filenumber = int(filenumber_match.group())\n",
        "          filenamenonumber = re.sub(filenumber_pattern, \"\", filename)\n",
        "      else:\n",
        "          filenumber = None\n",
        "          filenamenonumber = filename\n",
        "#construct input_video\n",
        "if isinstance(filenumber, (int)):\n",
        "  input_video = folder + filenamenonumber + str(filenumber) + \".mp4\"\n",
        "else:\n",
        "  input_video = folder + filenamenonumber + \".mp4\"\n",
        "#construct input_audio\n",
        "if isinstance(filenumber, (int)):\n",
        "  input_audio = folder + filenamenonumber + str(filenumber) + \".wav\"\n",
        "else:\n",
        "  input_audio = folder + filenamenonumber + \".wav\"\n",
        "\n",
        "#construct output_video\n",
        "output_filename = filename + output_suffix + \".mp4\"\n",
        "output_video = folder + filename + output_suffix + \".mp4\"\n",
        "video_pattern = r\"[^\\/]+$\"\n",
        "input_videofile = re.search(video_pattern, input_video).group()\n",
        "audio_pattern = r\"[^\\/]+$\"\n",
        "input_audiofile = re.search(audio_pattern, input_audio).group()\n",
        "temp_input = \"/content/Easy-Wav2Lip/temp/input.mp4\"\n",
        "temp_output = \"/content/Easy-Wav2Lip/temp/output.mp4\"\n",
        "temp_wav = \"/content/Easy-Wav2Lip/temp/input_audio.wav\"\n",
        "temp_avi = '/content/Easy-Wav2Lip/temp/result.avi'\n",
        "\n",
        "#remove last outputs\n",
        "directory_path = \"/content/Easy-Wav2Lip/temp\"\n",
        "if os.path.exists(directory_path):\n",
        "  shutil.rmtree(directory_path)\n",
        "os.makedirs(directory_path)\n",
        "\n",
        "!cp \"{input_path}\" \"{temp_input}\"\n",
        "\n",
        "\n",
        "#look for audio file\n",
        "\n",
        "print(\"Processing\" , input_videofile)\n",
        "if os.path.isfile(input_audio):\n",
        "  !cp \"{input_audio}\" \"{temp_wav}\"\n",
        "  if preview_input:\n",
        "    print(\"loading input video preview:\")\n",
        "    showVideo(input_video)\n",
        "    print(\"input audio:\" , input_audio)\n",
        "    display(Audio(temp_wav))\n",
        "    print(\"You may want to check now that they're the correct files!\")\n",
        "  else:\n",
        "    print(\"using\", input_audiofile, \"for audio\")\n",
        "\n",
        "#take audio from video file\n",
        "else:\n",
        "  temp_wav = temp_input\n",
        "  print(\"Using audio from video file\")\n",
        "  if preview_input:\n",
        "    print(\"loading input video preview:\")\n",
        "    showVideo(input_video)\n",
        "    print(\"You may want to check now that it's the correct video!\")\n",
        "\n",
        "rescaleFactor = str(round(1 // resolution_scale))\n",
        "pad_up = str(round(U * resolution_scale))\n",
        "pad_down = str(round(D * resolution_scale))\n",
        "pad_left = str(round(L * resolution_scale))\n",
        "pad_right = str(round(R * resolution_scale))\n",
        "\n",
        "ESRGAN_checkpoint = \"/weights/RealESRGAN_x4plus.pth\"\n",
        "\n",
        "#process length prediction\n",
        "#-------------------------------------------------------------------------------\n",
        "details = get_video_details(temp_input)\n",
        "input_resolution = int(details['resolution'])\n",
        "input_bitrate = float(details['bitrate'])\n",
        "input_length = float(details['length'])\n",
        "new_video_resolution = input_resolution\n",
        "new_video_bitrate = input_bitrate\n",
        "new_video_length = input_length\n",
        "new_video_resolution_scale = resolution_scale\n",
        "new_video_upscaler = upscaler\n",
        "stats_file = f'{upscaler}_with_{gpu_name}_stats.csv'\n",
        "object_key = 'wav2lip/' + stats_file\n",
        "num_lines = 1\n",
        "try:\n",
        "    s3.head_object(Bucket=bucket_name, Key=object_key)\n",
        "    s3.download_file(bucket_name, object_key, stats_file)\n",
        "    print(f\"found prediction data for {gpu_name} with {upscaler}\")\n",
        "    remove_duplicates(stats_file)\n",
        "    num_lines = count_lines(stats_file)\n",
        "except:\n",
        "    predicted_time = None\n",
        "    print(f\"no prediction data for {gpu_name} with {upscaler} yet\")\n",
        "if num_lines < 10:\n",
        "  print('But there isn\\'t enough prediction data for that combo yet to predict a processing time')\n",
        "  predicted_time = None\n",
        "else:\n",
        "  try:\n",
        "    predicted_time, r_squared = predict_processing_time(input_resolution, input_bitrate, input_length, resolution_scale, upscaler)\n",
        "    if r_squared <0:\n",
        "      print('Not much prediction data so prediction is unlikely to be accurate, but the more people process videos, the better it will get!')\n",
        "    if predicted_time is not None:\n",
        "      formatted_time = format_time(predicted_time[0])\n",
        "      confidence = '(~' + str(max(int(r_squared * 100),1)) + \"% confidence)\"\n",
        "      print()\n",
        "      print(f'Predicted processing time for this video is: {formatted_time} {confidence}')\n",
        "      print()\n",
        "  except:\n",
        "    print(f'unknown error trying to predict processing time :(')\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "#start processing timer\n",
        "start_time = time.time()\n",
        "\n",
        "#execute Wav2Lip & upscaler\n",
        "!python inference.py \\\n",
        "--face \"{temp_input}\" \\\n",
        "--audio \"{temp_wav}\" \\\n",
        "--outfile \"{temp_output}\" \\\n",
        "--pads $pad_up $pad_down $pad_left $pad_right \\\n",
        "--resize_factor $rescaleFactor \\\n",
        "{'--nosmooth ' if nosmooth else ''} {'-w ' + str(fidelity) if upscaler == \"codeformer\" else ''} {'--sr_path ' + ESRGAN_checkpoint if upscaler == \"ESRGAN\" else '--enhance_face ' + upscaler}\n",
        "\n",
        "#end processing timer\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "process_time = int(elapsed_time)\n",
        "formatted_process_time = format_time(elapsed_time)\n",
        "\n",
        "#rename temp file and move to correct directory\n",
        "if os.path.isfile(temp_output):\n",
        "  if os.path.isfile(output_video):\n",
        "    os.remove(output_video)\n",
        "  !cp \"{temp_output}\" \"{output_video}\"\n",
        "  if os.path.isfile(output_video):\n",
        "\n",
        "    #show output video\n",
        "    print()\n",
        "    print('Output video:')\n",
        "    showVideo(temp_output)\n",
        "    clear_output()\n",
        "  if GDrive:\n",
        "    print(f\"{filename}.mp4 successfully lip synched! Find it in the same folder as your input file.\")\n",
        "  else:\n",
        "    print(f\"{filename}.mp4 successfully lip synched!, click the 3 dots in the preview to download:\")\n",
        "  if predicted_time is not None: \n",
        "    print(f'Predicted processing time for this video was: {formatted_time} {confidence}')\n",
        "    print(f\"Actual Processing time: {formatted_process_time}\")\n",
        "  else:\n",
        "    print(f\"Processing time: {formatted_process_time}\")\n",
        "\n",
        "  #store processing stats and upload them back to the s3 bucket\n",
        "  store_processing_stats(input_resolution, input_bitrate, input_length, resolution_scale, upscaler, process_time)\n",
        "  try:\n",
        "      s3.upload_file(stats_file, bucket_name, object_key)\n",
        "      print(f\"Processing stats have been uploaded to improve processing time predictions for everyone :)\")\n",
        "  except:\n",
        "      print(\"Unable to upload processing stats, perhaps the file got too large?\")\n",
        "\n",
        "else:\n",
        "  print(f\"Processing failed! :(\")\n",
        "\n",
        "if os.path.isfile(stats_file):\n",
        " os.remove(stats_file)\n",
        "if os.path.isfile(temp_output):\n",
        "  showVideo(temp_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To do:\n",
        "* automatic batch processing (right now you can copy the above cell and paste it for how many videos you want to do in a row and change the file names on each cell)\n",
        "* support all video and audio types\n",
        "* option to render standard Wav2Lip? maybe."
      ],
      "metadata": {
        "id": "ILqz26z2g8pQ"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "fkoF-mm8CGfB"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}